:labname: New Features in Camel K

include::../include/00_0_Lab_Header.adoc[]

== {labname} Lab

:numbered:

== Introduction to New Features in Camel K

Debezium for Red Hat Integration is a distributed platform that captures database operations, creates data change event records for row-level operations, and streams change event records to Apache Kafka topics. Debezium is built on Apache Kafka and is deployed and integrated with AMQ Streams.

Debezium captures row-level changes to a database table and passes corresponding change events to AMQ Streams. Applications can read these change event streams and access the change events in the order in which they occurred.

With the Y22Q1 release of Red Hat^(R)^ Integration, you can now use AMQ Streams to deploy Debezium connectors by using a new AMQ Streams build mechanism that is based on Maven artifacts.

The Camel K provides cloud-native integration with the following main features:

* Knative Serving for autoscaling and scale-to-zero
* Knative Eventing for event-driven architectures
* Performance optimizations using Quarkus runtime by default
* Camel integrations written in Java or YAML DSL
* Monitoring of integrations using Prometheus in OpenShift
* Quickstart tutorials
* Kamelet Catalog for connectors to external systems such as AWS, Jira, and Salesforce
* Support for Timer and Log Kamelets
* Metering for Camel K Operator and pods

In this lab, we will cover the some of the features released in this quarter which include:

.Goals

* Camel K Serverless integration with Knative in an event-driven architecture
* Camel integrations written in Java or YAML DSL
* Monitoring of integrations using Prometheus in OpenShift
* Kamelet Catalog for connectors to external systems such as AWS, Jira, and Salesforce
* Summary

== Camel K Serverless integration with Knative in an event-driven architecture

In this section, you will deploy a Camel K integration with OpenShift Serverless in an event-driven architecture. This demonstrates the idiomatic way of using Camel K in Knative for building event-driven applications. It leverages the Knative eventing broker as the central point that lets various services communicate via event pub/sub. It also shows how Camel K can be used for connecting the Knative event mesh with external systems, with integrations that can play the roles of "event source" or "event sink".

.Scenario
This exercise will demonstrate a simplified trading system that analyzes price variations of Bitcoins (BTC / USDT), using different prediction algorithms, and informs downstream services when it's time to buy or sell bitcoins (via CloudEvents). It uses real data from the bitcoin exchange market, obtained in real time via the https://www.binance.com Http service.

The architecture is composed of the following Camel K integrations:

* market-source: creates a live feed of BTC/USDT events, from the Bitcoin exchange market, containing the current value of a bitcoin and related information.
* simple-predictor: it is triggered by variations in the BTC/USDT value and produces "suggested actions", as events for downstream services, telling if it's time to buy or sell at a specific value.
* better-predictor: it's an alternative prediction algorithm (prediction algorithms are pluggable in the architecture) that is wiser and generates less buy/sell events respect to the simple-predictor.
* silly-investor: this service believes blindly to the simple-predictor and buys/sells Bitcoins whenever the predictor suggests it.
* cautious-investor-service: this is a service built by another team that needs suggestions from the better-predictor but it needs to receive them via a pre-existing public REST API that it shared also with external entities.
* cautious-investor-adapter-sink: this Camel K integration listens to buy/sell events from the better-predictor and transforms them into REST calls to the * cautious-investor-service using its public API.

All Camel K integrations described above (except the market-source which needs to poll the market for new data), are "serverless", meaning that they scale down to zero when they don't receive new events or requests.

=== Preparing the cluster

.Procedure

. Create a new project for this section of the lab:
+
[source,bash]
----
$ oc new-project lab-04-knative
----

.  To start using Camel K, we need to install the operator by running the below command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: lab-04-knative-og
  namespace: lab-04-knative
spec:
  targetNamespaces:
  - lab-04-knative
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: red-hat-camel-k
  namespace: lab-04-knative
spec:
  channel: stable
  name: red-hat-camel-k
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

. Confirm if the operator installed successfull by running `oc get csv` and find an entry related to `red-hat-camel-k-operator` in phase *Succeeded*:
+
[source,bash]
----
NAME                              DISPLAY                         VERSION   REPLACES                                         PHASE
red-hat-camel-k-operator.v1.6.5   Red Hat Integration - Camel K   1.6.5     red-hat-camel-k-operator.v1.6.4-0.1648537022.p   Succeeded
----
[NOTE]
Since we are using marketplace, the CSV version may be different than what is shown here

.  Next we need to install the Integration Platform.  The IntegrationPlatform CR is the resource used to control the behavior of the Camel K Operator such as the desired state and the status of the object at current time.  You install the IntegrationPlatform by running this command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: camel.apache.org/v1
kind: IntegrationPlatform
metadata:
  name: camel-k
  labels:
    app: "camel-k"
  namespace: lab-04-knative
EOF
----

. We now need to install the Openshift Serverless Operator (Knative) to later install both Knative Serving and Knative Eventing.  To do this we first need to create a new namespace for the operator by running this command:
+
[source,bash]
----
$ oc create namespace openshift-serverless
----

. Next we install the operator:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: openshift-serverless-og
  namespace: openshift-serverless
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: serverless-operator
  namespace: openshift-serverless
spec:
  channel: stable
  name: serverless-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

. Confirm if the operator installed successfull by running `oc get csv` and find an entry related to `serverless-operator` in phase *Succeeded*:
+
[source,bash]
----
NAME                          DISPLAY                        VERSION   REPLACES                      PHASE
serverless-operator.v1.21.1   Red Hat OpenShift Serverless   1.21.1    serverless-operator.v1.21.0   Succeeded
----

. Once the operator is installed, we need to install Knative-Serving.  Knative Serving is ideal for running your application services inside Kubernetes by providing a more simplified deployment syntax with automated scale-to-zero and scale-out based on HTTP load. The Knative platform will manage your serviceâ€™s deployments, revisions, networking and scaling. Knative Serving exposes your service via an HTTP URL and has a lot of sane defaults for its configurations.
+
We first need to create a `knative-serving` namespace:
+
[source,bash]
----
$ oc create namespace knative-serving
----

. To create the `KnativeServing` resource, run the below command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operator.knative.dev/v1alpha1
kind: KnativeServing
metadata:
  name: knative-serving
  namespace: knative-serving
spec: {}
EOF
----

. To check that Knative Serving is installed successfully, we need to confirm the status of the `Conditions` of the resource.  Run the below command and identify the `status` fields of the returned json:
+
[source,bash]
----
$ oc get knativeserving knative-serving -n knative-serving -o jsonpath="{.status.conditions}" | python -m json.tool
----
+
[NOTE]
If you do not have python installed, copy the output generated of `oc get knativeserving knative-serving -n knative-serving -o jsonpath="{.status.conditions}"` to a json formatting tool of your choice.
+
The value of all `status` fields should be `true`.

. Next we install Knative Eventing.  Knative eventing is a way to create, send, and verify events in your cloud-native environment.
+
We first need to create a `knative-eventing` namespace:
+
[source,bash]
----
$ oc create namespace knative-eventing
----

. To install Knative Eventing, run the below command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
pipe heredoc> apiVersion: operator.knative.dev/v1alpha1
kind: KnativeEventing
metadata:
  name: knative-eventing
  namespace: knative-eventing
spec: {}
EOF
----

. To check that Knative Eventing is installed successfully, we need to confirm the status of the `Conditions` of the resource.  Run the below command and identify the `status` fields of the returned json:
+
[source,bash]
----
$ oc get knativeeventing knative-eventing -n knative-eventing -o jsonpath="{.status.conditions}" | python -m json.tool
----

=== Enabling the Knative Eventing Broker

.Procedure

. Switch back to your main project:
+
[source,bash]
----
$ oc project lab-04-knative
----

. The central piece of the event mesh that we're going to create is the Knative Eventing broker. It is a publish/subscribe entity that Camel K integrations will use to publish events or subscribe to it in order to being triggered when events of specific types are available. Subscribers of the eventing broker are Knative serving services, that can scale down to zero when no events are available for them.
+
To enable the eventing broker, we create a default broker in the current namespace using the Knative CLI:
+
[source,bash]
----
$ kn broker create default
----

=== Push Bitcoin market data to the mesh

.Procedure

. Run the below command to clone the repository containing the lab artifacts and navigate to the folder lab-04-knative:
+
[source,bash]
----
$ git clone git@github.com/redhat-gpte-devopsautomation/hands_on_integration_y22q1_lab.git
$ cd hands_on_integration_y22q1_lab/lab-04-knative
----

. We'll create a (market-source.yaml) integration, using Camel YAML DSL, with the role of taking live data from the Bitcoin market and pushing it to the event mesh, using the market.btc.usdt event type:
+
[source,bash]
----
$ kamel run market-source.yaml --logs
----
+
The command above will run the integration and wait for it to run, then it will show the logs in the console.  To exit the log view, hit ctrl+c on the terminal window. The integration will keep running on the cluster.

=== Run some prediction algorithms

.Procedure

. The market data feed available in the mesh can be now used to create different prediction algorithms that can publish events when they believe it's the right time to sell or buy bitcoins, depending on the trend of the exchange.
+
In this example, we're going to run the same (basic) algorithm with different parameters*, obtaining two predictors. The algorithm is basic and it's just computing if the BTC variation respect to the last observed value is higher than a threshold (expressed in percentage). The algorithm is bound to the event mesh via the `Predictor.java` integration file.
+
The first predictor that we're going to run is called `simple-predictor`:
+
[source,bash]
----
$ kamel run --name simple-predictor -p predictor.name=simple Predictor.java -t knative-service.max-scale=1 --logs
----
+
[NOTE]
We're setting the maximum number of instances of the autoscaling service to 1 because it runs a basic algorithm that does not support scaling (stores data in memory)
+
The command above will deploy the integration and wait for it to run, then it will show the logs in the console.  To exit the log view, hit ctrl+c on the terminal window. The integration will keep running on the cluster.

. The second one (better-predictor) will be just a variation of the first, with a different threshold:
+
[source,bash]
----
$ kamel run --name better-predictor -p predictor.name=better -p algorithm.sensitivity=0.0005 Predictor.java -t knative-service.max-scale=1
----
+
You can play with the sensitivity of the better-predictor to make it do prediction faster or slower and see the effects on the downstream services.

. Ensure that both predictors are running:
+
[source,bash]
----
$ kamel get
NAME			    PHASE	KIT
better-predictor	Running	lab-04-knative/kit-c9sb9md321256ktt5jb0
market-source		Running	lab-04-knative/kit-c9sb72l321256ktt5jag
simple-predictor	Running	lab-04-knative/kit-c9sb9md321256ktt5jb0
----
+
You should wait also for the better-predictor integration to be running before proceeding.

=== Run a subscriber investor service

.Procedure

. We are going to deploy a service that will listen to the events of type `predictor.simple` (i.e. generated by the simple predictor) and blindly executing the suggested actions (in this example, printing the action to the logs).
+
It's thus called `silly-investor``. To run it:
+
[source,bash]
----
$ kamel run SillyInvestor.java --logs
----
+
The command above will run the integration and wait for it to run, then it will show the logs in the console. You should be able to see that the investor service is doing actions suggested by the simple predictions.
+
To exit the log view, hit ctrl+c on the terminal window. The integration will keep running on the cluster.

=== Connecting an external investor service

.Procedure

. We'll simulate the presence of an existing investor service that is not directly connected to the mesh. It exposes a well defined API that is available in the `CautiousInvestorService.java` file.
+
The service could have been developed with any language or framework, but since in this example it's developed with Camel K, it is automatically turned into an autoscaling serverless service.
+
To run it:
+
[source,bash]
----
$ kamel run CautiousInvestorService.java -w
----
+
The -w flag (stands for "wait") in command above will make sure the command terminates on the terminal only when the integration is fully deployed.

. Now we can deploy the CautiousInvestorAdapterSink.java integration, that will bring events from the "better" predictor right into the service APIs, after a simple transformation:
+
[source,bash]
----
$ kamel run CautiousInvestorAdapterSink.java -w
----

. Once the adapter sink is running, you can look at the external service logs to see if it's receiving recommendations. The command for printing the logs is:
+
[source,bash]
----
$ kamel logs cautious-investor-service
----
+
To exit the log view, just hit ctrl+c on the terminal window.
+
[NOTE]
If the pod does not run or the logs are not showing up, then probably there's nothing to show. Since the "better" predictor is not sensitive to small variations of the Bitcoin value, it's possible that the service will go down after some time to save resources. To force the service to come up again, you can edit the `CautiousInvestorAdapterSink.java` to change the starting URI from knative:event/predictor.better to knative:event/predictor.simple, then run the integration again. It's likely that the events generated by the simple predictor will trigger the downstream services more often.

=== When the market closes...

.Procedure

. Bitcoin market never closes, but closing hours are expected to be present for standard markets. We're going to simulate a closing on the market by stopping the source integration.
+
When the market closes and updates are no longer pushed into the event mesh, all downstream services will scale down to zero. This includes the two prediction algorithms, the two services that receive events from the mesh and also the external investor service.
+
To simulate a market close, we will delete the market-source:
+
[source,bash]
----
$ kamel delete market-source
----
+
At the end of the process, no user pods will be running.

. To simulate now a reactivation of the market in the morning, you can create again the market-source:
+
[source,bash]
----
$ kamel run market-source.yaml
----

. Pods now will start again to run, one after the other, as soon as they are needed:
+
[source,bash]
----
$ oc get pod
----

=== Cleanup

.Procedure

To cleanup everything, execute the following command:
[source,bash]
----
$ oc delete project lab-04-knative
----

== Camel integrations written in Java or YAML DSL

This section of the lab demonstrates how to run a simple Java and YAML integration in the cloud on OpenShift, apply configuration and routing to an integration, and run an integration as a Kubernetes CronJob.

=== Preparing the cluster

We will start by creating a new project and installing the Red Hat Camel K operator and an Integration Platform for running your new integrations.

.Procedure

. Create a new project for this section of the lab:
+
[source,bash]
----
$ oc new-project lab-04-camel-basic
----

.  To start using Camel K, we need to install the operator and Integration Platform CR by running the below command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: lab-04-camel-basic-og
  namespace: lab-04-camel-basic
spec:
  targetNamespaces:
  - lab-04-camel-basic
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: red-hat-camel-k
  namespace: lab-04-camel-basic
spec:
  channel: stable
  name: red-hat-camel-k
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: camel.apache.org/v1
kind: IntegrationPlatform
metadata:
  name: camel-k
  labels:
    app: "camel-k"
  namespace: lab-04-camel-basic
EOF
----

. Confirm if the operator installed successfull by running `oc get csv` and find an entry related to `red-hat-camel-k-operator` in phase *Succeeded*:
+
[source,bash]
----
NAME                              DISPLAY                         VERSION   REPLACES                                         PHASE
red-hat-camel-k-operator.v1.6.5   Red Hat Integration - Camel K   1.6.5     red-hat-camel-k-operator.v1.6.4-0.1648537022.p   Succeeded
----

=== Running a basic Java integration

This exercise contains a simple Camel K integration that periodically prints a "Hello World..." message.
The integration is all contained in a single file named `JavaBasic.java`.

.Procedure

. Navigate to the git repository you cloned in the previous section and select the `lab-04-camel-basic` subdirectory.  If you have not done this already, execute the following commands:
+
[source,bash]
----
$ git clone git@github.com/redhat-gpte-devopsautomation/hands_on_integration_y22q1_lab.git
$ cd hands_on_integration_y22q1_lab/lab-04-camel-basic
----

. Open the file `JavaBasic.java`.  It contains a simple route which intermittently prints a message to logger.
+
[source,java]
----
...
from("timer:java?period=1000")
  .setHeader("example")
    .constant("Java")
  .setBody()
    .simple("Hello World! Camel K route written in ${header.example}.")
  .to("log:info");
...
----

. We're ready to run the integration on our `camel-basic` project in the cluster.
+
Use the following command to run it in "dev mode", in order to see the logs in the integration terminal:
+
[source,bash]
----
$ kamel run JavaBasic.java --dev
...
[1] 2022-05-10 05:17:03,730 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello World! Camel K route written in Java.]
[1] 2022-05-10 05:17:04,724 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello World! Camel K route written in Java.]
[1] 2022-05-10 05:17:05,723 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello World! Camel K route written in Java.]
[1] 2022-05-10 05:17:06,723 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello World! Camel K route written in Java.]
...
----
+
If everything is ok, after the build phase finishes, you should see the Camel integration running and continuously printing "Hello World!..." in the terminal window.

. When running in dev mode, you can change the integration code and let Camel K redeploy the changes automatically.  Open `JavaBasic.java` and change "Hello World" into "Ciao Mondo", then save the file.  You should see the new integration starting up in the terminal window and replacing the old one.
+
[source,bash]
----
...
2] 2022-05-10 05:18:58,580 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Ciao Mondo! Camel K route written in Java.]
[2] 2022-05-10 05:18:59,568 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Ciao Mondo! Camel K route written in Java.]
[2] 2022-05-10 05:19:00,568 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Ciao Mondo! Camel K route written in Java.]
[2] 2022-05-10 05:19:01,569 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Ciao Mondo! Camel K route written in Java.]
[2] 2022-05-10 05:19:02,570 INFO  [info] (Camel (camel-1) thread #0 - timer://java) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Ciao Mondo! Camel K route written in Java.]
...
----

. To exit dev mode and terminate the execution, hit `ctrl+c`.
+
[NOTE]
When you terminate a "dev mode" execution, the remote integration will be deleted. This gives the experience of a local program execution, but the integration is actually running in the remote cluster.

. To keep the integration running and not linked to the terminal, you can run it without "dev mode", just run:
+
[source,bash]
----
$ kamel run JavaBasic.java
----

. After executing the command, you should be able to see it among running integrations:
+
[source,bash]
----
$ oc get integrations
NAME         PHASE     KIT                        REPLICAS
java-basic   Running   kit-c9sv8cbqhmgmgn6vsl7g   1
----

. An integration named `java-basic` should be present in the list and it should be in status `Running`. There is also a `kamel get` command which is an alternative way to list all running integrations.
+
[source,bash]
----
NAME		    PHASE	  KIT
java-basic	Running	lab-04-camel-basic/kit-c9sv8cbqhmgmgn6vsl7g
----

. The second example is a bit more complex as it shows how to configure the integration using external properties and
also a simple content-based router.  The integration is contained in a file named `Routing.java`.
+
Open the file in an editor of your choice to view it.
+
The routes use two configuration properties named `items` and `priority-marker` that should be provided using an external file such
as the `routing.properties`.  The `Routing.java` file shows how to inject properties into the routes via property placeholders and also the usage of the `@PropertyInject` annotation.  To run the integration, we should link the integration to the property file providing configuration for it:
+
[source,bash]
----
$ kamel run Routing.java --property-file routing.properties --dev
----
+
Wait for the integration to be running (you should see the logs streaming in the terminal window).  To exit dev mode and terminate the execution, hit `ctrl+c`.

=== Running a basic YAML integration

This section explains how to develop a simple Camel K integration in YAML DSL. Writing an integration in YAML to be deployed using Camel K is the same as defining your routing rules in Camel.

You can use any Camel component directly in your integration routes. Camel K automatically handles the dependency management and imports all the required libraries from the Camel catalog using code inspection.

.Procedure

. Enter the kamel init command to generate a simple YAML integration file:
[source,bash]
----
$ kamel init hello.camelk.yaml
----

. Open the generated integration file in your IDE and edit as appropriate. For example, the hello.camelk.yaml integration automatically includes the Camel timer and log components to help you get started:
+
[source,yaml]
----
# Write your routes here, for example:
- from:
    uri: "timer:yaml"
    parameters:
      period: "1s"
    steps:
      - set-body:
          constant: "Hello Camel K from yaml"
      - to: "log:info"
----

. Run the Camel K integration:
+
[source,bash]
----
$ kamel run hello.camelk.yaml
integration "hello" created
----

. To view the logs of the deployed integration, run the following command:
+
[source,bash]
----
$ oc logs -l camel.apache.org/integration=hello --follow
2022-05-11 05:06:50,058 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:51,058 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:52,058 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:53,059 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:54,059 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:55,060 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
2022-05-11 05:06:56,060 INFO  [info] (Camel (camel-1) thread #0 - timer://yaml) Exchange[ExchangePattern: InOnly, BodyType: String, Body: Hello Camel K from yaml]
----
+
To exit following the log, hit `ctrl+c`.

=== Cleanup

To cleanup everything, execute the following command:

[source,bash]
----
$ oc delete project lab-04-camel-basic
----

== Monitoring of integrations using Prometheus in OpenShift

Camel K monitoring is based on the Prometheus monitoring system: https://prometheus.io/. This chapter explains how to use the available options for monitoring Red Hat Integration - Camel K integrations at runtime. You can use the Prometheus Operator that is already deployed as part of OpenShift Monitoring to monitor your own applications.

=== Enabling user workload monitoring in OpenShift

OpenShift 4.3 or higher includes an embedded Prometheus Operator already deployed as part of OpenShift Monitoring. This section explains how to enable monitoring of your own application services in OpenShift Monitoring. This option avoids the additional overhead of installing and managing a separate Prometheus instance.

. Procedure

. Enter the following command to check if the cluster-monitoring-config ConfigMap object exists in the openshift-monitoring project:
+
[source,bash]
----
$ oc -n openshift-monitoring get configmap cluster-monitoring-config
Error from server (NotFound): configmaps "cluster-monitoring-config" not found
----

. Create the cluster-monitoring-config ConfigMap if this does not already exist:
+
[source,bash]
----
$ oc -n openshift-monitoring create configmap cluster-monitoring-config
configmap/cluster-monitoring-config created
----

. Edit the cluster-monitoring-config ConfigMap:
+
[source,bash]
----
$ oc -n openshift-monitoring edit configmap cluster-monitoring-config
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true
----

=== Configuring Camel K integration metrics

You can configure monitoring of Camel K integrations automatically using the Camel K Prometheus trait at runtime. This automates the configuration of dependencies and integration Pods to expose a metrics endpoint, which is then discovered and displayed by Prometheus. The Camel Quarkus MicroProfile Metrics extension automatically collects and exposes the default Camel K metrics in the OpenMetrics format.

. Procedure

. Create a new project for this section of the lab:
+
[source,bash]
----
$ oc new-project lab-04-camel-monitoring
----

.  As with the previous section, to start using Camel K, we need to install the operator and the IntegrationPlatform CR:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: lab-04-camel-monitoring-og
  namespace: lab-04-camel-monitoring
spec:
  targetNamespaces:
  - lab-04-camel-monitoring
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: red-hat-camel-k
  namespace: lab-04-camel-monitoring
spec:
  channel: stable
  name: red-hat-camel-k
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
apiVersion: camel.apache.org/v1
kind: IntegrationPlatform
metadata:
  name: camel-k
  labels:
    app: "camel-k"
  namespace: lab-04-camel-monitoring
EOF
----

. Navigate to your lab directory and select the folder `lab-04-camel-monitoring`.  This folder contains a simple Camel K integration class `SimpleIntegration.java` which logs a message periodically.

. Enter the following command to run your Camel K integration with the Prometheus trait enabled:
+
[source,java]
----
$ kamel run SimpleIntegration.java -t prometheus.enabled=true
----
+
Alternatively, you can enable the Prometheus trait globally once, by updating the integration platform as follows:
+
[source,bash]
----
$ oc patch ip camel-k --type=merge -p '{"spec":{"traits":{"prometheus":{"configuration":{"enabled":true}}}}}'
----

. To view monitoring of Camel K integration metrics in the embedded Prometheus, login to you Openshift console in your browser and select *Observe > Metrics* on the left menu option.

. For example, in order to view the uptime of a running Camel integration, enter `application_camel_context_uptime_seconds` under *Insert metric at Cursor* and click *Run Querires*.  You should see the metric displayed at the bottom of your page with the relevant values.

. For more information on creating your own custom Camel K integration metrics, visit https://access.redhat.com/documentation

== Kamelet Catalog for connectors to external systems such as AWS, Jira, and Salesforce

When you install the Camel K operator, it includes a catalog of Kamelets that you can use in your Camel K integrations.  Red Hat now provides support for coonectors to external systems such as AWS, Jira and Salesforce.  In this section of the lab, we will browse the Kamelet Catalog and view the `jira-source` Kamelet external connector.

.Procedure

. Create a new project for this section of the lab:
+
[source,bash]
----
$ oc new-project lab-04-kamelet-catalog
----

.  To start using the Kamel Catalog, we need to install the Camel K operator by running the below command:
+
[source,bash]
----
$ cat << EOF | oc create -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: lab-04-kamelet-catalog-og
  namespace: lab-04-kamelet-catalog
spec:
  targetNamespaces:
  - lab-04-kamelet-catalog
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: red-hat-camel-k
  namespace: lab-04-kamelet-catalog
spec:
  channel: stable
  name: red-hat-camel-k
  source: redhat-operators
  sourceNamespace: openshift-marketplace
EOF
----

. Run the following command to view the full catalog:
+
[source,bash]
----
$ oc get kamelets
----

. To view the `jira-source` kamelet, run the below command:
+
[source,bash]
----
$ oc get kamelet jira-source -o yaml
----

. The following table summarizes the configuration options available for the jira-source Kamelet:
+
|===
|Property |Name |Description |Type |Example

|jiraUrl*
|Jira URL
|The URL of your instance of Jira
|string
|"http://my_jira.com:8081"

|password*
|Password
|The password to access Jira
|string
|

|username*
|Username
|The username to access Jira
|string
|

|jql
|JQL
|A query to filter issues
|
|"project=MyProject"
|===
+
[NOTE]
Fields marked with an asterisk (*) are mandatory.

== Summary


Congratulations, you have finished the lab. Here is a recap:

* Deployed a Camel K integration with OpenShift Serverless in an event-driven architecture leveraging the Knative eventing broker for event pub/sub. It also demonstrated Knative Serving for autoscaling and scale-to-zero.
* Deployed a Java and YAML integration to Openshift as well as demonstrated passing runtime properties to the integration.
* Monitor integrations using embedded Prometheus in Openshift Monitoring
* Viewing the Kamelet Catalog and list of Kamelets as an overview of the configuration of an external connector.

Thanks for taking the course.